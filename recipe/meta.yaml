{% set name = "litellm" %}
{% set version = "1.40.2" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/litellm-{{ version }}.tar.gz
  sha256: 1f5dc4eab7100962c3a2985c7d8c13070ff5793b341540d19b98a2bd85955cb0

build:
  entry_points:
    - litellm = litellm:run_server
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 0

requirements:
  host:
    - python >=3.8
    - poetry-core
    - wheel
    - pip
  run:
    - python >=3.8.1,<4.0,!=3.9.7
    - openai >=1.27.0
    - python-dotenv >=0.2.0
    - tiktoken >=0.4.0
    - importlib-metadata >=6.8.0
    - tokenizers
    - click
    - jinja2 >=3.1.2,<4.0.0
    - aiohttp
    - requests >=2.31.0,<3.0.0
  run_constrained:
    - uvicorn >=0.22.0,<0.23.0
    - gunicorn >=21.2.0,<22.0.0
    - fastapi >=0.109.1,<0.110.0
    - backoff *
    - pyyaml >=6.0.1,<7.0.0
    - rq *
    - orjson >=3.9.7,<4.0.0
    - apscheduler >=3.10.4,<4.0.0
    - fastapi-sso >=0.10.0,<0.11.0
    - PyJWT >=2.8.0,<3.0.0
    - python-multipart >=0.0.6,<0.0.7
    - cryptography 41.0.3

test:
  imports:
    - litellm
  commands:
    - pip check
    - litellm --help
  requires:
    - pip

about:
  summary: Library to easily interface with LLM API providers
  home: https://github.com/BerriAI/litellm
  license: MIT
  license_file: LICENSE

extra:
  recipe-maintainers:
    - jan-janssen
