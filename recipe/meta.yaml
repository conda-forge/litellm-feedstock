{% set name = "litellm" %}
{% set version = "1.77.5" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/litellm-{{ version }}.tar.gz
  sha256: 8e8a83b49c4a6ae044b1a1c01adfbdef72b0031b86f1463dd743e267fa1d7b99

build:
  entry_points:
    - litellm = litellm:run_server
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 1

requirements:
  host:
    - python {{ python_min }}
    - poetry-core
    - wheel
    - pip
  run:
    - pondpond >=1.4.1
    - fastuuid >=0.13.0
    - httpx >=0.23.0
    - python >={{ python_min }}
    - openai >=1.99.5
    - python-dotenv >=0.2.0
    - tiktoken >=0.7.0
    - importlib-metadata >=6.8.0
    - tokenizers
    - click
    - jinja2 >=3.1.2
    - aiohttp >=3.10
    - pydantic >=2.5.0
    - jsonschema >=4.22.0
  run_constrained:
    - uvicorn >=0.29.0
    - uvloop >=0.21.0
    - gunicorn >=23.0.0
    - fastapi >=0.115.5
    - pyyaml >=6.0.1
    - orjson >=3.9.7
    - apscheduler >=3.10.4
    - pyjwt >=2.8.0
    - python-multipart >=0.0.18
    - cryptography >=43.0.1
    - azure-identity >=1.15.0
    - azure-keyvault-secrets >=4.8.0
    - google-cloud-kms >=2.21.3
    - pynacl >=1.5.0
    - websockets >=13.1.0
    - boto3 >=1.34.34
    - mcp >=1.9.3
    - rich >13.7.1
    - diskcache >=5.6.1
    # not yet available on conda-forge
    - prisma >=0.11.0
    - resend >=0.8.0
    - fastapi-sso >=0.16.0
    - redisvl >=0.4.1
    - litellm-proxy-extras >=0.2.6
    - litellm-enterprise >=0.1.10

test:
  imports:
    - litellm
  commands:
    - pip check
    - litellm --help
  requires:
    - pip
    - python {{ python_min }}

about:
  summary: Library to easily interface with LLM API providers
  home: https://github.com/BerriAI/litellm
  license: MIT
  license_file: LICENSE

extra:
  recipe-maintainers:
    - m-rossi
    - jan-janssen
