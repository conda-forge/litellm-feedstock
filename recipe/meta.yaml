{% set name = "litellm" %}
{% set version = "1.68.1" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/litellm-{{ version }}.tar.gz
  sha256: 301fe0457ac059806009352b6578821351125cfdf35e3a0ab8c43a8336852667

build:
  entry_points:
    - litellm = litellm:run_server
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 0

requirements:
  host:
    - python {{ python_min }}
    - poetry-core
    - wheel
    - pip
  run:
    - httpx >=0.23.0
    - python >={{ python_min }}
    - openai >=1.68.2,<1.76.0
    - python-dotenv >=0.2.0
    - tiktoken >=0.7.0
    - importlib-metadata >=6.8.0
    - tokenizers
    - click
    - jinja2 >=3.1.2,<4.0.0
    - aiohttp
    - pydantic >=2.0.0,<3.0.0
    - jsonschema >=4.22.0,<5.0.0
  run_constrained:
    - uvicorn >=0.29.0,<0.30.0
    - uvloop >=0.21.0,<0.22.0
    - gunicorn >=22.0.0,<23.0.0
    - fastapi >=0.111.5,<1.0.0
    - pyyaml >=6.0.1,<7.0.0
    - orjson >=3.9.7,<4.0.0
    - apscheduler >=3.10.4,<4.0.0
    - pyjwt >=2.8.0,<3.0.0
    - python-multipart >=0.0.18,<0.0.19
    - cryptography >=43.0.1,<44.0.0
    - azure-identity >=1.15.0,<2.0.0
    - azure-keyvault-secrets >=4.8.0,<5.0.0
    - google-cloud-kms >=2.21.3,<3.0.0
    - pynacl >=1.5.0,<2.0.0
    # not yet available on conda-forge
    - prisma >=0.11.0,<0.12.0
    - resend >=0.8.0,<0.9.0
    - fastapi-sso >=0.16.0,<0.17.0

test:
  imports:
    - litellm
  commands:
    - pip check
    - litellm --help
  requires:
    - pip
    - python {{ python_min }}

about:
  summary: Library to easily interface with LLM API providers
  home: https://github.com/BerriAI/litellm
  license: MIT
  license_file: LICENSE

extra:
  recipe-maintainers:
    - m-rossi
    - jan-janssen
